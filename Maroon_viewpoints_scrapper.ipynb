{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping op-eds/editorials from the University of Chicago's Maroon's [Viewpoints](https://www.chicagomaroon.com/viewpoints/) page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import queue\n",
    "import json\n",
    "import sys\n",
    "import csv\n",
    "import urllib\n",
    "import collections\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Crawl the Viewpoints page and identify metadata of each article (e.g. name of the author, link to the article, title of the article and the type of the article (op-ed, letter, editorial etc.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_crawl(starting_url):\n",
    "    '''\n",
    "    Scrapes the full webpage from a starting url.\n",
    "    \n",
    "    Inputs:\n",
    "        starting_url: string\n",
    "    Returns:\n",
    "        a soup object\n",
    "    '''    \n",
    "    page = urllib.request.urlopen(starting_url)\n",
    "    if page is not None:\n",
    "        soup = bs4.BeautifulSoup(page, \"html\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faraaz/anaconda/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/faraaz/anaconda/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "full_doc = page_crawl(\"https://www.chicagomaroon.com/viewpoints/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_doc_text = full_doc.find_all(class_=[\"media-heading\", \"text-muted  media-heading\", \"inline section-footer\", \" media-heading\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_attributes(all_doc_text):\n",
    "    '''\n",
    "    Extracts the attributes (link of the article, article title, author and article type) of the Viewpoints articles.\n",
    "    \n",
    "    Inputs:\n",
    "        - the text of the Viewpoints home webpage\n",
    "    \n",
    "    Returns:\n",
    "        - four lists corresponding to each attribute (link of the article, article title, author and article type).\n",
    "    '''\n",
    "\n",
    "    article_title_list = []\n",
    "    article_link_list = []\n",
    "    contributor_names_list = []\n",
    "    article_type_list = []\n",
    "\n",
    "    for line in all_doc_text:\n",
    "        # find the link to the article and the title of the article\n",
    "        if line.name == \"h2\" or line.name == \"h4\":\n",
    "\n",
    "            if line.find(class_=\"plain-link\") is not None:\n",
    "                article_link = line.find(class_=\"plain-link\")['href']\n",
    "                article_link_list.append(article_link)\n",
    "\n",
    "                article_title = line.find(class_=\"plain-link\").text.strip()\n",
    "                article_title_list.append(article_title)\n",
    "\n",
    "        # find the name(s) of the contributor(s) of the Viewpoints article\n",
    "        elif line.name == \"p\":\n",
    "            contributors = line.find_all(class_=\"plain-link\")\n",
    "\n",
    "            # if condition to store one contributor, otherwise create a tuple to record multiple contributors\n",
    "            if len(contributors) == 1:\n",
    "                contributor_names_list.append(contributors[0].text)\n",
    "\n",
    "            else:\n",
    "                all_names = ()\n",
    "                # find out the names of all the contributors of a single article\n",
    "                for contributor_name in contributors:\n",
    "                    #following line of code inspiration from: https://stackoverflow.com/questions/16730339/python-add-item-to-the-tuple\n",
    "                    all_names = all_names + (contributor_name.text,)\n",
    "                contributor_names_list.append(all_names)\n",
    "\n",
    "        # find the type of the article (oped, letter to the editor, editorial board etc.)\n",
    "        # assumption: I'm considering all articles as the viewpoints expressed by the students of the University of Chicago in my project\n",
    "        elif line.name == \"small\":\n",
    "            article_type = line.text\n",
    "            article_type_list.append(article_type)\n",
    "    \n",
    "    return article_link_list, article_title_list, contributor_names_list, article_type_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if articles data (name, article type etc.) is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_link_list, article_title_list, contributor_names_list, article_type_list = get_article_attributes(full_doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contributor_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_type_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The article type list is not complete because the first 16 articles did not have a tag associated with them. Upon a quick inspection, it seems like all of them are OP-ED, so I'll create an entry for them in the article_type_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_26_article_types = ['OP-EDS']*(len(contributor_names_list)-len(article_type_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_article_type_list = first_26_article_types + article_type_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_article_type_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scrap the texts of the articles, organize meta data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first convert the relative url into the absolute url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_article_link_list = []\n",
    "for article_link in article_link_list:\n",
    "    new_article_link = 'https://www.chicagomaroon.com' + article_link\n",
    "    new_article_link_list.append(new_article_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.chicagomaroon.com/article/2018/5/11/hasty-calculations-reclaiming-math/',\n",
       " 'https://www.chicagomaroon.com/article/2018/5/15/violence-words/',\n",
       " 'https://www.chicagomaroon.com/article/2018/5/8/dear-bartlett-tale-dining-fall/',\n",
       " 'https://www.chicagomaroon.com/article/2018/5/4/defense-criticizing-uchicago/',\n",
       " 'https://www.chicagomaroon.com/article/2018/5/1/uchicago-place-people-color/']"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show only top 5\n",
    "new_article_link_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now crawl through every webpage and find the relevant text\n",
    "\n",
    "def get_text_and_byline(full_articles_links):\n",
    "    '''\n",
    "    Get the text of the articles and their bylines.\n",
    "    \n",
    "    Input:\n",
    "        - the links of the articles\n",
    "    \n",
    "    Returns:\n",
    "        - a list of lists where each list inside contains text corresponding to a particular article\n",
    "        - a list of strings where each string is text corresponding to a particular article\n",
    "        - a list of bylines\n",
    "    '''\n",
    "\n",
    "    text_list_of_lists = []\n",
    "    byline_list = []\n",
    "    texts_list_final_without_join = []\n",
    "\n",
    "    for article_link in full_articles_links:\n",
    "\n",
    "        article_text = page_crawl(article_link)\n",
    "        texts = article_text.find(\"div\", class_=\"article-content\")\n",
    "        texts_list = texts.find_all({\"p\", \"em\", \"i\"})\n",
    "\n",
    "        texts_list_final = []\n",
    "        tag_name_list = []\n",
    "\n",
    "        for text_ in texts_list:\n",
    "            tag_name = text_.name\n",
    "            k = text_.text.strip()\n",
    "            tag_name_list.append(tag_name)\n",
    "            texts_list_final.append(k)\n",
    "\n",
    "        if (tag_name_list[-1] == \"em\") or (tag_name_list[-1] == \"i\"):\n",
    "            byline_list.append(texts_list_final[-1])\n",
    "            texts_list_final = texts_list_final[:-1]\n",
    "\n",
    "        else:\n",
    "            byline_list.append(\"unidentified byline\")\n",
    "\n",
    "        texts_list_final_without_join.append(texts_list_final)\n",
    "        texts_list_final = \" \".join(texts_list_final)\n",
    "        text_list_of_lists.append(texts_list_final)\n",
    "        \n",
    "    return texts_list_final_without_join, text_list_of_lists, byline_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faraaz/anaconda/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/faraaz/anaconda/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "texts_list_final_without_join, text_list_of_lists, byline_list = get_text_and_byline(new_article_link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Meera Santhanam is a first-year in the College.',\n",
       " 'Lucas Du is a first-year in the College.',\n",
       " 'Katia Kukucka is a first-year in the College.',\n",
       " 'unidentified byline',\n",
       " 'Soulet Ali is a second-year in the College.',\n",
       " 'Zahra Nassar is a first-year in the College.',\n",
       " 'Natalie Denby is a third-year in the College.',\n",
       " 'Alexa Perlmutter is a first-year in the College.',\n",
       " 'Natalie Denby is a third year in the College majoring in public policy studies.',\n",
       " 'Lucas Du is a first year in the College.',\n",
       " 'Meera Santhanam is a first-year in the College.',\n",
       " 'Soulet Ali is a second-year in the College.',\n",
       " 'unidentified byline',\n",
       " 'unidentified byline',\n",
       " 'Atlantic',\n",
       " 'Natalie Denby is a third-year in the College majoring in public policy studies.',\n",
       " 'David Mihalyfy (Ph.D. ’17) studied in the Divinity School’s History of Christianity program.',\n",
       " 'Isaac Tannenbaum is a student in the College.',\n",
       " 'Kavia Khosla,\\xa0Gena Lenti, and\\xa0Katie Ellis are first-years at the Pritzker School of Medicine.',\n",
       " 'Alyssa Rodriguez, Julie Xu, Soreti Teshome, Tunisia Tai, Diego Cardenas, Ada Alozie, Kenya Senecharles, Eric Holmberg, Ben Glover, Claire Moore, Larissa Santana, José Heredia, Shayla Harris, and Sara Zubi',\n",
       " 'David Liu is a first year in the College.',\n",
       " 'Michael Lemay is a third-year at the University of Chicago.',\n",
       " 'Deblina Mukherjee is a first-year in the College.',\n",
       " 'Annabella Gong is a third-year economics major in the College, serving as president of Phoenix Sustainability Initiative. Caitlin Piccirillo-Stosser is a fourth-year economics and public policy studies double major in the College, serving as the student coordinator of both the Frizzell Series and EAF.',\n",
       " 'Daniel Moline is a second-year graduate student in the Biological Sciences Division.',\n",
       " 'Zoe Bean is a first-year in the College.',\n",
       " 'Liana Fu and Paola Del Toro on behalf of UChicago United',\n",
       " 'unidentified byline',\n",
       " 'Kenneth W. Warren',\n",
       " 'UChicago United is a coalition of multicultural student organizations, including Organization of Black Students (OBS), PanAsia, MEChA, Organization of Latin American Students (OLAS), and African Caribbean Students Association (UChicago). UC United was formed to make the University of Chicago campus more inclusive for students of marginalized backgrounds and identities.',\n",
       " 'unidentified byline',\n",
       " 'unidentified byline',\n",
       " 'Michele Rasmussen\\nDean of Students in the University\\nThe University of Chicago',\n",
       " 'Meegan Stock Niemira (A.B. ’91)',\n",
       " 'unidentified byline',\n",
       " 'unidentified byline',\n",
       " 'unidentified byline',\n",
       " 'unidentified byline',\n",
       " 'Morganne Ramsey recused herself from this editorial because she interned with the Biss campaign.',\n",
       " 'The Maroon',\n",
       " 'unidentified byline',\n",
       " 'Katie Akin recused herself from this editorial due to her previous coverage of the proposed major. Michael Perry has also recused himself',\n",
       " 'Editorial Board',\n",
       " 'Spencer Dembner recused himself from this editorial due to his involvement in Grounds of Being coverage.',\n",
       " \"Editor's Note: News editor Peter Grieve has recused himself from this editorial due to his involvement in coverage of the Tax Cuts and Jobs Act.\",\n",
       " 'The Maroon',\n",
       " 'Sonia Schlesinger, Peter Grieve, Lee Harris, Deepti Sailappan, and Eugenia Ko have recused themselves from this editorial due to their previous involvement in unionization coverage.',\n",
       " 'Editorial Board',\n",
       " 'Editorial Board',\n",
       " 'Editorial Board',\n",
       " 'Patrick Lou recused himself from the writing of this editorial due to his membership in an FCS fraternity.\\u200b',\n",
       " 'unidentified byline']"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byline_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_df(some_list):\n",
    "    '''\n",
    "    Collects meta data and the text of the article in a dictionary and converts it into a dataframe.\n",
    "    '''\n",
    "    \n",
    "    # initialize a dictionary\n",
    "    viewpoints_dict = {}\n",
    "\n",
    "    for index, article_type in enumerate(some_list):\n",
    "        viewpoints_dict[index] = []\n",
    "        viewpoints_dict[index].append(article_link_list[index])\n",
    "        viewpoints_dict[index].append(article_title_list[index])\n",
    "        viewpoints_dict[index].append(contributor_names_list[index])\n",
    "        viewpoints_dict[index].append(article_type_list[index])\n",
    "        viewpoints_dict[index].append(texts_list_final_without_join[index])\n",
    "        viewpoints_dict[index].append(text_list_of_lists[index])\n",
    "        viewpoints_dict[index].append(byline_list[index])\n",
    "    \n",
    "    # convert dictionary into a datframe\n",
    "    df = pd.DataFrame(viewpoints_dict)\n",
    "    df = df.transpose()\n",
    "    df.columns = ['article_link', 'title', 'author', 'article_type', 'article_text_in_list', 'article_text_str', 'byline']\n",
    "    df.head()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>article_type</th>\n",
       "      <th>article_text_in_list</th>\n",
       "      <th>article_text_str</th>\n",
       "      <th>byline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/article/2018/5/11/hasty-calculations-reclaimi...</td>\n",
       "      <td>Hasty Calculations: Reclaiming Math</td>\n",
       "      <td>Meera Santhanam</td>\n",
       "      <td>OP-EDS</td>\n",
       "      <td>[“I am not a math person.” I think many of us ...</td>\n",
       "      <td>“I am not a math person.” I think many of us c...</td>\n",
       "      <td>Meera Santhanam is a first-year in the College.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/article/2018/5/15/violence-words/</td>\n",
       "      <td>The Violence of Words</td>\n",
       "      <td>Lucas Du</td>\n",
       "      <td>OP-EDS</td>\n",
       "      <td>[Content warning: sexual violence, Content war...</td>\n",
       "      <td>Content warning: sexual violence Content warni...</td>\n",
       "      <td>Lucas Du is a first-year in the College.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/article/2018/5/8/dear-bartlett-tale-dining-fall/</td>\n",
       "      <td>Dear Bartlett: A Tale Of a Dining Fall</td>\n",
       "      <td>Katia Kukucka</td>\n",
       "      <td>OP-EDS</td>\n",
       "      <td>[We’ve all heard the hot (or, should I say, th...</td>\n",
       "      <td>We’ve all heard the hot (or, should I say, the...</td>\n",
       "      <td>Katia Kukucka is a first-year in the College.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/article/2018/5/4/defense-criticizing-uchicago/</td>\n",
       "      <td>In Defense of Criticizing UChicago</td>\n",
       "      <td>Alexa Perlmutter</td>\n",
       "      <td>OP-EDS</td>\n",
       "      <td>[A few weeks ago when prospective students flo...</td>\n",
       "      <td>A few weeks ago when prospective students floo...</td>\n",
       "      <td>unidentified byline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/article/2018/5/1/uchicago-place-people-color/</td>\n",
       "      <td>UChicago: No Place for People of Color</td>\n",
       "      <td>Soulet Ali</td>\n",
       "      <td>OP-EDS</td>\n",
       "      <td>[Prospective PoC (people of color) undergradua...</td>\n",
       "      <td>Prospective PoC (people of color) undergraduat...</td>\n",
       "      <td>Soulet Ali is a second-year in the College.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  /article/2018/5/11/hasty-calculations-reclaimi...   \n",
       "1                 /article/2018/5/15/violence-words/   \n",
       "2  /article/2018/5/8/dear-bartlett-tale-dining-fall/   \n",
       "3    /article/2018/5/4/defense-criticizing-uchicago/   \n",
       "4     /article/2018/5/1/uchicago-place-people-color/   \n",
       "\n",
       "                                    title            author article_type  \\\n",
       "0     Hasty Calculations: Reclaiming Math   Meera Santhanam       OP-EDS   \n",
       "1                   The Violence of Words          Lucas Du       OP-EDS   \n",
       "2  Dear Bartlett: A Tale Of a Dining Fall     Katia Kukucka       OP-EDS   \n",
       "3      In Defense of Criticizing UChicago  Alexa Perlmutter       OP-EDS   \n",
       "4  UChicago: No Place for People of Color        Soulet Ali       OP-EDS   \n",
       "\n",
       "                                article_text_in_list  \\\n",
       "0  [“I am not a math person.” I think many of us ...   \n",
       "1  [Content warning: sexual violence, Content war...   \n",
       "2  [We’ve all heard the hot (or, should I say, th...   \n",
       "3  [A few weeks ago when prospective students flo...   \n",
       "4  [Prospective PoC (people of color) undergradua...   \n",
       "\n",
       "                                    article_text_str  \\\n",
       "0  “I am not a math person.” I think many of us c...   \n",
       "1  Content warning: sexual violence Content warni...   \n",
       "2  We’ve all heard the hot (or, should I say, the...   \n",
       "3  A few weeks ago when prospective students floo...   \n",
       "4  Prospective PoC (people of color) undergraduat...   \n",
       "\n",
       "                                            byline  \n",
       "0  Meera Santhanam is a first-year in the College.  \n",
       "1         Lucas Du is a first-year in the College.  \n",
       "2    Katia Kukucka is a first-year in the College.  \n",
       "3                              unidentified byline  \n",
       "4      Soulet Ali is a second-year in the College.  "
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maroon_df = dict_to_df(article_type_list)\n",
    "maroon_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves the dataframe to a csv\n",
    "maroon_df.to_csv(\"maroon_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
